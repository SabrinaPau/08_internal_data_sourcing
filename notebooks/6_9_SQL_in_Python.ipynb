{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SQL in Python - Connecting to and retrieving data from PostgreSQL\n",
    "Previously, you have learned how to connect to a SQL database by using a SQL client such as DBeaver.  \n",
    "Apart from connecting to databases, DBeaver also allows you to run SQL queries against the database, create new tables and populate them with data as well as retrieving the data.  \n",
    "Populating tables with data that you have locally on your machine usually requires you to save it in a file, like a CSV, and import it using the DBeaver UI.  \n",
    "Often, before you reached the final step of uploading your dataset, you have performed data cleaning procedures to bring your data into shape.  \n",
    "This is usually done in Python (or R). This means we would import the data into Python, clean it, export it to a CSV file, import it into DBeaver and upload the data into the database.  \n",
    "This process requires multiple steps and more than one software. Fortunately, we can reduce the steps by connecting to the database from Python directly, eliminating the need for a separate SQL client. \n",
    "  \n",
    "**This notebook will not only teach you how to connect to a database and query its data in Python directly, but also how to automate the process using custom functions and modules.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating a connection to a PostgreSQL database with Python\n",
    "The go-to package in Python for connecting to a PostgreSQL database is called <ins>psycopg2</ins>. Check out their official website here: https://www.psycopg.org/docs/.  \n",
    "Complete the code below to import the package."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import psycopg2 package\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to create a connection to our PostgreSQL database you need the following information:\n",
    "- host = the address of the machine the database is hosted on\n",
    "- port = the virtual gate number through which communication will be allowed\n",
    "- database = the name of the database\n",
    "- user = the name of the user\n",
    "- password = the password of the user\n",
    "\n",
    "Don't worry, we will provide this information to you.  \n",
    "The function from the psycopg package to create a connection is called <ins>connect()</ins>.  \n",
    "connect() expects the parameters listed above as input in order to connect to the database.  \n",
    "We created a separate file called sql.py to store the connect() function together with the database credentials. This file is listed in the gitignore and will therefore never be pushed to a remote repository protecting the sensitive database credentials from becoming publicly available. To have the connection in this notebook we're simply importing the connection object conn from the sql.py file. Later in the notebook we will come back to this concept, so don't worry about it right now. For now open the sql.py file, enter the credentials and run the code block below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import connection object conn\n",
    "from sql import conn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, let's have a look at the conn variable to see what we're working with."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print connection object conn\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The conn variable is a connection object or more precisely, a database session. This means that currently we have one open connection to our database.  \n",
    "This connection will stay open until we manually close it. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrieving data from the database\n",
    "Before we can use our connection to get data, we have to create a cursor. A cursor allows Python code to execute PostgreSQL commmands in a database session.  \n",
    "A cursor has to be created with the <ins>cursor()</ins> method of our connection object conn."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create cursor: cur\n",
    "cur = conn._______\n",
    "\n",
    "# Print cursor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, in order to retrieve data from our database, we have to use our cursor and its <ins>execute()</ins> method. The execute() method takes a SQL query as parameter and executes it.  \n",
    "Complete the code below to select all columns and the top 5 rows from the flights table."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Use execute() and print top 5 rows from flights \n",
    "cur.execute('SELECT ___ FROM ___ LIMIT ___')\n",
    "\n",
    "# Print cursor\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "When printing the cursor, we still don't get any data output.  \n",
    "Why? Because our cursor behaves similar to our connection. The result in stored inside the cursor object and can't be accessed by simply printing it.  \n",
    "Instead we need to use the <ins>fetchall()</ins> method, which fetches all rows of a query result.  \n",
    "Complete the code below and print the results of the SQL query."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Use fetchall()\n",
    "cur.________"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There we go! Finally we have the output of our SQL query.  \n",
    "Now, before we summarise everything we have done, let's close our database connection to free up database resources for our colleagues.\n",
    "\n",
    "In order to close a database connection we have to use the <ins>close()</ins> method of our connection ebject.\n",
    "Complete the code below and terminate the database connection."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Close database connection\n",
    "conn.________"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perfect, let's summarise the steps we have performed above:\n",
    "1. (Install and) Import the psycopg2 package\n",
    "2. Create a database connection object with the connect() method\n",
    "3. Create a cursor for the database connection with the cursor() method\n",
    "4. Use the execute() method of the cursor to execute a SQL query\n",
    "5. Use the fetchall() method of the cursor to retrieve the results of the SQL query\n",
    "6. Close the database connection with the close() method\n",
    "\n",
    "In total we needed about 6 steps to connect to the databse and retrieve data.  \n",
    "Even though we probably won't have to go through all the steps over and over again when querying data, this is still somewhat of a tedious process. On top of that, there is another inconvenience when it comes to the output. The format of the data we retrieve from the database is a list. As analysts we almost always want to have our data in a dataframe, since it makes exploring and cleaning data a lot easier.\n",
    "\n",
    "Let's fix these problems and do the following:\n",
    "1. Write a custom function that performs all of the steps above\n",
    "2. Change the code so the SQL output is in a dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Automating data retrieval with a custom function: get_data()\n",
    "Instead of having to write multiple lines of code whenever we want to query data from Python, we're going to make our lives easier by writing a custom function that will execute all of the necessary steps automatically. For this, we're going to define a custom function called <ins>get_data()</ins> below. This function should only expect one argument: query. The function should be able to take any query as a string, create a connection to the database, execute the query, output the data and close the connection.\n",
    "\n",
    "Complete the code below so that the get_data() function prints the output of any SQL query we pass it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_data(_____):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        conn = ___________________\n",
    "\t\t\n",
    "        # create a cursor\n",
    "        cur = __________\n",
    "        \n",
    "\t    # execute a statement\n",
    "        cur.____________\n",
    "\n",
    "        # display the results of the query\n",
    "        cur.____________\n",
    "       \n",
    "\t    # close the connection to the PostgreSQL database\n",
    "        _________\n",
    "\n",
    "    # the code below makes the function more robust, you can ignore this part\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it's time to check if your function works. Use the get_data() function below to return the top five rows of the flights table."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print top 5 rows from flights\n",
    "get_data('____________')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It works, awesome! Now whenever we want to connect to our database and retrieve data we can simply use the get_data() function, how convenient! Unforturnately, we can't call ourselves Python hackers yet, because we still need to solve the problem with the output format."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Changing the SQL query output format from list to dataframe\n",
    "We know already, that the output format of the fetchall() function is a list, which is inconvenient to work with. Luckily there is a function that let's us read a SQL query directly into a dataframe. It's called <ins>read_sql_query()</ins> and can be found in the pandas package.\n",
    "The function expects a SQL query as the first argument and a connection (object) to a database as the second argument.\n",
    "Complete the code below and return the output in a dataframe."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Print top 5 rows from flights table using read_sql_query()\n",
    "__.read_sql_query('_________________', ____)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This output looks like a dataframe. Was it really that easy? Let's check if the output really is a dataframe.  \n",
    "Complete the code below and check if the output is of type dataframe."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print type of read_sql_query() output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It really is a dataframe! Wow, that was very easy and what's even better: we can don't need a cursor and also don't need to run the execute() and fetchall() functions anymore!  \n",
    "The only thing left is to change our get_data() function and replace the steps that are not needed anymore with our new read_sql_query function.  \n",
    "Copy the content of the code block where we define the get_data() function and paste it into the code block below. Then, adjust the code by replacing redundant steps with our new read_sql_query function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Copy get_data() and implement read_sql_query()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's make sure the function works by returning the first 5 rows of the flights table below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print top 5 rows from flights\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have the data in a dataframe, it's easy to apply all the different data exploration and cleaning techniques we have learned already. We don't have to do that right now, but it will become very useful in the future!  \n",
    "Congratulations, from now on you can call yourself a Python hacker!  \n",
    "\n",
    "But wait..., what if I told you there is a way of making your get_data() function even more powerful?  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Automating data retrieval using a Python module\n",
    "Before I will tell how to make your function even more powerful, let's take a step back and look at the prerequisites for using the get_data() function and what limitations apply.  \n",
    "In order to use our get_data() function anywhere in our jupyter notebook, we need to define it once with the correct connection details.  \n",
    "But what if we have multiple jupyter notebooks in our repository and we want to use this in other notebooks as well? How could we do that?  \n",
    "As with all things in life: <ins>it depends</ins>.  \n",
    "\n",
    "Remember that when you start a jupyter notebook, you simultaneously start a kernel that will then load your virtual environment and execute any Python code you feed it.  \n",
    "Every package you load and every function you define will be available in that jupyter notebook only.  \n",
    "Now imagine you have defined the get_data() function in only one of your jupyter notebooks, but you have multiple notebooks in your repository where you would like to use this function.\n",
    "To be able to do that you would have to add the function definition to each notebook. In reality you would simply duplicate your code over and over, which should always be avoided. While this wouldn't mean the end of the world, the real problem occurs if we ever wanted to change the connection details inside the function. In that case, we would have to find and change each function definition in each file, which not only increases the likelihood of errors but could become a tedious unnecessarily time consuming task.  \n",
    "\n",
    "Now that we know about the downsides, can you think of a another, better solution? If you don't have any idea, think about Python packages or more specifically about why and how we use them.  \n",
    "The answer is, we import Python packages because they include predefined functions that we can then use in any of our Python scripts, which is exactly what we want to do with our function. You're probably thinking: \"But we don't have a package and we also don't want to create a package for just function and publish it to the offical Python library\". That's true but fortunately, we don't have to. Instead we can use a built-in Python functionality called <ins>modules</ins>.    \n",
    "Instead of giving you a detailed explanation what modules are and what they do, let's create a python module and use it instead.\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "Please perform the following steps:\n",
    "1. Open sql.py and import all Python packages necessary for the get_data() function to work\n",
    "2. Insert the definition of the get_data() function\n",
    "3. Import the Python file into this jupyter notebook below the same way you normally import packages\n",
    "4. Execute the get_data() function\n",
    "\n",
    "**Important: To make sure we're using the function from our get_data.py module and not the one we defined earlier in this jupyter notebook we need to reference it by alias**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import get_data() from sql.py\n",
    "from ___ import _______ as gd\n",
    "\n",
    "# Print top 5 rows from flights\n",
    "gd.________('SELECT * FROM flights LIMIT 5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Worked like a charm!  \n",
    "Great, let's summarise: Whenever we want to use a custom function in any other jupyter notebook in our repository, we  \n",
    "\n",
    "1. create a new Python module,\n",
    "2. add the necessary packages and function definitions,\n",
    "3. and import it into our jupyter notebook using the standard import snytax\n",
    "\n",
    "If you still don't understand what modules are and why we did what we did, check out the offical [documentation](https://docs.python.org/3/tutorial/modules.html) about modules or reach out to us. It's important you understand this concepts since we will be working with python modules in future jupyter notebooks.\n",
    "\n",
    "Congratulations for making it through this notebook, you deserve to call yourself a badass Python hacker!"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('sql-practice': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "fbe0aead5cca8d2ea82be07e886227a87e9bb2a57fe7325eef0acd6ed9d1683b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}